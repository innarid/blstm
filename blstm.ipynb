{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Применение реккурентных нейронных сетей для задачи разметки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "import pymorphy2\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка текстов диалогов человека и оператора Tinkoff. Диалоги содержат слова, помеченные категориями (например: ВАЛЮТА, МЕСТО СНЯТИЯ, НАЗВАНИЕ БАНКА, ТИП КАРТЫ). Необходимо разработать алгоритм, позволяющий находить данные категории в неразмеченном диалоге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('slotfilling-data.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for item in data:\n",
    "        entities = item['entities']\n",
    "        if len(entities)>0:\n",
    "            y_item = {}\n",
    "            for entity in entities:\n",
    "                y_item[entity['title']] = {\n",
    "                    'start_pos': entity['start_pos'],\n",
    "                    'end_pos': entity['end_pos'],\n",
    "                    'text': entity['text']\n",
    "                }\n",
    "            X.append(item['chat'])\n",
    "            y.append(y_item)\n",
    "            \n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1: Здравствуйте. Считается ли преревод денег с карты Тинькофф на карту сбербанка операцией изъятия денежных средств?\\n2: Перевод хотите осуществлять с кредитной карты?\\n2: Нет, это разные операции.\\n1: Какую сумму без процентов я могу перевести с-карты Тинькофф дебетовой на карту другого банка?\\n2: 11 111 руб. в расчетном периоде без комиссии\\n2: Свыше 11 111 руб. комиссия составит 1,1%, минимум 11 руб.\\n1: Как сумму я могу перевести на карту Тинькофф без комиссии ?\\n1: И какой месячный лимит снятия наличных средств с карты Тинькофф в банкоматах?\\n2: Если перевод был на карту нашего банка, то это внутрибанковский перевод. по тарифу они без комиссии вне зависимости от суммы.\\n2: По Вашему тарифу снимать денежные средства без комиссии Вы можете при условии снятия средств не менее 1 111 руб. за одну операция и не более 111 111 руб. за расчетный период. .\\n2: Отмечу, что сторонний банк может устанавливать свою комиссию за использование его банкомата. Как правило, информация о комиссии появляется на дисплее банкомата до совершения операции\\n',\n",
       " {'ВАЛЮТА': {'end_pos': 361, 'start_pos': 356, 'text': 'руб.'},\n",
       "  'ТИП_КАРТЫ': {'end_pos': 268, 'start_pos': 259, 'text': 'дебетовой'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0],y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ВАЛЮТА', 'ВРЕМЯ_ДАТА_СНЯТИЯ', 'ЗА_ГРАНИЦЕЙ', 'МЕСТО_СНЯТИЯ',\n",
       "       'НАЗВАНИЕ_БАНКА', 'НОМЕР_ТЕЛЕФОНА', 'РАЗМЕР_КОМИССИИ',\n",
       "       'СУММА_СНЯТИЯ', 'ТАРИФ_КАРТЫ', 'ТИП_КАРТЫ'], dtype='<U17')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_slots =np.unique(np.array([item for y_item in y for item in list(y_item.keys())]))\n",
    "possible_slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# W2V n dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка уже обученной в банке модели Word2Vec и самостоятельное обучение модели Word2Vec на корпусе из предложений, из которых состоят диалоги, для преобразования каждого слова в численный вектор. Близкие по смыслу слова преобразуются в близкие по косинусной мере вектора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "w2v_model = word2vec.Word2Vec.load('word2vec/w2v_model_tfidf_size300_window5_mc2.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "patt=re.compile(\"[a-zA-Zа-яА-Я0-9]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для приведения разных форм (падежей, склонений, спряжений) слов к одному виду используется лемматизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_sent_parse=[]\n",
    "for i in range(len(X)):\n",
    "    S=re.split(\"\\n1:|\\n2:\",X[i])\n",
    "    W_sent_parse.append([morph.parse(word.lower())[0].normal_form for word in  re.findall(patt, S[0][3:])])\n",
    "    for sent in range(1,len(S)):\n",
    "        W_sent_parse.append([morph.parse(word.lower())[0].normal_form for word in  re.findall(patt, S[sent])])\n",
    "W_sent_parse=np.array(W_sent_parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "На получившихся корпусах предложений из нормализированных слов обучается Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-13 21:15:53,976 : INFO : collecting all words and their counts\n",
      "2018-02-13 21:15:53,978 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-02-13 21:15:54,010 : INFO : PROGRESS: at sentence #10000, processed 124723 words, keeping 4549 word types\n",
      "2018-02-13 21:15:54,042 : INFO : PROGRESS: at sentence #20000, processed 246680 words, keeping 6347 word types\n",
      "2018-02-13 21:15:54,114 : INFO : PROGRESS: at sentence #30000, processed 391620 words, keeping 7359 word types\n",
      "2018-02-13 21:15:54,122 : INFO : collected 7522 word types from a corpus of 410945 raw words and 31734 sentences\n",
      "2018-02-13 21:15:54,125 : INFO : Loading a fresh vocabulary\n",
      "2018-02-13 21:15:54,152 : INFO : min_count=0 retains 7522 unique words (100% of original 7522, drops 0)\n",
      "2018-02-13 21:15:54,153 : INFO : min_count=0 leaves 410945 word corpus (100% of original 410945, drops 0)\n",
      "2018-02-13 21:15:54,196 : INFO : deleting the raw counts dictionary of 7522 items\n",
      "2018-02-13 21:15:54,200 : INFO : sample=0.001 downsamples 75 most-common words\n",
      "2018-02-13 21:15:54,201 : INFO : downsampling leaves estimated 281392 word corpus (68.5% of prior 410945)\n",
      "2018-02-13 21:15:54,203 : INFO : estimated required memory for 7522 words and 100 dimensions: 9778600 bytes\n",
      "2018-02-13 21:15:54,237 : INFO : resetting layer weights\n",
      "2018-02-13 21:15:54,372 : INFO : training model with 2 workers on 7522 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-02-13 21:15:55,397 : INFO : PROGRESS: at 56.27% examples, 782365 words/s, in_qsize 3, out_qsize 0\n",
      "2018-02-13 21:15:56,154 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-13 21:15:56,158 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-13 21:15:56,160 : INFO : training on 2054725 raw words (1406224 effective words) took 1.8s, 791974 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model_wv_parse= word2vec.Word2Vec(W_sent_parse, min_count=0,size=100, window=5, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-13 21:16:00,347 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('втб11', 0.9688775539398193),\n",
       " ('сбербанковский', 0.9488134980201721),\n",
       " ('мкб', 0.948691725730896),\n",
       " ('росбанк', 0.9410445094108582),\n",
       " ('хач', 0.9386786222457886),\n",
       " ('райффайзть', 0.935751736164093),\n",
       " ('земляной', 0.9315928816795349),\n",
       " ('райффайзенбанк', 0.9306322932243347),\n",
       " ('калининград', 0.9305438995361328),\n",
       " ('пров', 0.9304080605506897)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv_parse.wv.most_similar_cosmul(positive=['втб'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Создание DataFrame с номером диалога, словом, нормализованным словом, номерами начальных и конечных символов слов, обученным самостоятельно word2vec и обученным в tinkoff word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3857/3857 [06:44<00:00,  9.54it/s]\n"
     ]
    }
   ],
   "source": [
    "text=[]\n",
    "for t in tqdm(range(len(X))):\n",
    "    for i in re.finditer(patt, X[t]):\n",
    "        if i.start()>2 and ((i.start(),i.end()) not in [(j.start()+1,j.end()-1) for j in re.finditer(\"\\n1:|\\n2:\", X[t])]):\n",
    "            try:\n",
    "                text.append((t,i.group(),morph.parse(i.group().lower())[0].normal_form,i.start(), i.end(),\n",
    "                         model_wv_parse.wv[morph.parse(i.group().lower())[0].normal_form],\n",
    "                         w2v_model.wv[morph.parse(i.group().lower())[0].normal_form]))\n",
    "            except:\n",
    "                text.append((t,i.group(),morph.parse(i.group().lower())[0].normal_form,i.start(), i.end(),\n",
    "                         model_wv_parse.wv[morph.parse(i.group().lower())[0].normal_form],\n",
    "                         'not_found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_parse=pd.DataFrame(text, columns=['text','word','word_parse','start','end','my_wv','tinkoff_wv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410945, 410945)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([len(sent) for sent in W_sent_parse]).sum(),len(data_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word</th>\n",
       "      <th>word_parse</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>my_wv</th>\n",
       "      <th>tinkoff_wv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Здравствуйте</td>\n",
       "      <td>здравствовать</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.6812069, 1.5810897, 0.7941233, 0.11929614, ...</td>\n",
       "      <td>[1.4132696, 2.0395722, -0.1583433, 1.1966592, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Считается</td>\n",
       "      <td>считаться</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.026889628, 0.010631667, 0.3676494, 0.01146...</td>\n",
       "      <td>[1.9538485, -0.29608145, 0.44123772, 1.9070864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ли</td>\n",
       "      <td>ли</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>[1.0615267, 0.9635242, 0.9209784, -0.5370277, ...</td>\n",
       "      <td>[0.13136159, -0.23199584, 1.2246481, -1.821377...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>преревод</td>\n",
       "      <td>преревод</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>[-0.0025141998, 0.015409501, 0.0006466113, 0.0...</td>\n",
       "      <td>[-0.040791918, 0.085409895, -0.05206685, -0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>денег</td>\n",
       "      <td>деньга</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>[1.5603204, 0.4778464, 0.7217178, -0.5819099, ...</td>\n",
       "      <td>[-0.36978602, 2.2669377, 0.54615086, -3.661288...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text          word     word_parse  start  end  \\\n",
       "0     0  Здравствуйте  здравствовать      3   15   \n",
       "1     0     Считается      считаться     17   26   \n",
       "2     0            ли             ли     27   29   \n",
       "3     0      преревод       преревод     30   38   \n",
       "4     0         денег         деньга     39   44   \n",
       "\n",
       "                                               my_wv  \\\n",
       "0  [0.6812069, 1.5810897, 0.7941233, 0.11929614, ...   \n",
       "1  [-0.026889628, 0.010631667, 0.3676494, 0.01146...   \n",
       "2  [1.0615267, 0.9635242, 0.9209784, -0.5370277, ...   \n",
       "3  [-0.0025141998, 0.015409501, 0.0006466113, 0.0...   \n",
       "4  [1.5603204, 0.4778464, 0.7217178, -0.5819099, ...   \n",
       "\n",
       "                                          tinkoff_wv  \n",
       "0  [1.4132696, 2.0395722, -0.1583433, 1.1966592, ...  \n",
       "1  [1.9538485, -0.29608145, 0.44123772, 1.9070864...  \n",
       "2  [0.13136159, -0.23199584, 1.2246481, -1.821377...  \n",
       "3  [-0.040791918, 0.085409895, -0.05206685, -0.11...  \n",
       "4  [-0.36978602, 2.2669377, 0.54615086, -3.661288...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Добавление в получившуюся таблицу таргетов по всем категориям из all possible_slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ВАЛЮТА\n",
      "ВРЕМЯ_ДАТА_СНЯТИЯ\n",
      "ЗА_ГРАНИЦЕЙ\n",
      "МЕСТО_СНЯТИЯ\n",
      "НАЗВАНИЕ_БАНКА\n",
      "НОМЕР_ТЕЛЕФОНА\n",
      "РАЗМЕР_КОМИССИИ\n",
      "СУММА_СНЯТИЯ\n",
      "ТАРИФ_КАРТЫ\n",
      "ТИП_КАРТЫ\n"
     ]
    }
   ],
   "source": [
    "targets=[]\n",
    "for j in range(len(possible_slots)):\n",
    "    cat=possible_slots[j]\n",
    "    print(cat)\n",
    "    for i in range(len(y)):\n",
    "        try:\n",
    "            targets.append((j+1,cat,i,y[i][cat]['start_pos'],y[i][cat]['end_pos'],y[i][cat]['text']))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_targ=pd.DataFrame(targets, columns=['cat_number','cat','text','start','end','word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_parse['targ']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8303 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 8303/8303 [10:47<00:00, 12.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data_targ))):\n",
    "\n",
    "    text=np.array(data_parse['text']==data_targ.iloc[i]['text'])\n",
    "    pos=np.all([text,np.array(data_parse['start']<data_targ.iloc[i]['end']), \n",
    "                                                np.array(data_parse['end']>data_targ.iloc[i]['start'])],axis=0)\n",
    "    data_parse['targ'][pos]=data_targ.iloc[i]['cat_number']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word</th>\n",
       "      <th>word_parse</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>my_wv</th>\n",
       "      <th>tinkoff_wv</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Здравствуйте</td>\n",
       "      <td>здравствовать</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.6812069, 1.5810897, 0.7941233, 0.11929614, ...</td>\n",
       "      <td>[1.4132696, 2.0395722, -0.1583433, 1.1966592, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Считается</td>\n",
       "      <td>считаться</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.026889628, 0.010631667, 0.3676494, 0.01146...</td>\n",
       "      <td>[1.9538485, -0.29608145, 0.44123772, 1.9070864...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ли</td>\n",
       "      <td>ли</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>[1.0615267, 0.9635242, 0.9209784, -0.5370277, ...</td>\n",
       "      <td>[0.13136159, -0.23199584, 1.2246481, -1.821377...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>преревод</td>\n",
       "      <td>преревод</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>[-0.0025141998, 0.015409501, 0.0006466113, 0.0...</td>\n",
       "      <td>[-0.040791918, 0.085409895, -0.05206685, -0.11...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>денег</td>\n",
       "      <td>деньга</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>[1.5603204, 0.4778464, 0.7217178, -0.5819099, ...</td>\n",
       "      <td>[-0.36978602, 2.2669377, 0.54615086, -3.661288...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text          word     word_parse  start  end  \\\n",
       "0     0  Здравствуйте  здравствовать      3   15   \n",
       "1     0     Считается      считаться     17   26   \n",
       "2     0            ли             ли     27   29   \n",
       "3     0      преревод       преревод     30   38   \n",
       "4     0         денег         деньга     39   44   \n",
       "\n",
       "                                               my_wv  \\\n",
       "0  [0.6812069, 1.5810897, 0.7941233, 0.11929614, ...   \n",
       "1  [-0.026889628, 0.010631667, 0.3676494, 0.01146...   \n",
       "2  [1.0615267, 0.9635242, 0.9209784, -0.5370277, ...   \n",
       "3  [-0.0025141998, 0.015409501, 0.0006466113, 0.0...   \n",
       "4  [1.5603204, 0.4778464, 0.7217178, -0.5819099, ...   \n",
       "\n",
       "                                          tinkoff_wv  targ  \n",
       "0  [1.4132696, 2.0395722, -0.1583433, 1.1966592, ...     0  \n",
       "1  [1.9538485, -0.29608145, 0.44123772, 1.9070864...     0  \n",
       "2  [0.13136159, -0.23199584, 1.2246481, -1.821377...     0  \n",
       "3  [-0.040791918, 0.085409895, -0.05206685, -0.11...     0  \n",
       "4  [-0.36978602, 2.2669377, 0.54615086, -3.661288...     0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Каждому слову сопоставляется токен: 1-самое часто употребляемое слово,..., MAX_NB_WORDS(количество слов в словаре) - самое редкое слово. Предложения и диалоги превращаются в токенизированные последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = len(model_wv_parse.wv.vocab)\n",
    "EMBEDDING_DIM = len(model_wv_parse.wv.word_vec('1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sent_to_token=[]\n",
    "for i in range(len(W_sent_parse)):  \n",
    "    sent_to_token.append(\" \".join(W_sent_parse[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3857/3857 [00:07<00:00, 526.89it/s]\n"
     ]
    }
   ],
   "source": [
    "dialog_to_token=[]\n",
    "for i in tqdm(range(data_parse['text'].max()+1)):\n",
    "    dialog_to_token.append(\" \".join(np.array(data_parse[data_parse['text']==i]['word_parse'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS+1)\n",
    "tokenizer.fit_on_texts(sent_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentences = tokenizer.texts_to_sequences(sent_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dialogs = tokenizer.texts_to_sequences(dialog_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_parse['tokenizer']=np.array([word_index[w] for w in np.array(data_parse['word_parse'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для embedding слоя нейронной сети создается embedding matrix. Строка этой матрицы под номер i соответствует i-му токену-слову и представляется собой вектор, полученный при помощи word2vec, этого слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_embedding_matrix = np.zeros((MAX_NB_WORDS+1, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if word in model_wv_parse.wv.vocab:\n",
    "        my_embedding_matrix[i] = model_wv_parse.wv.word_vec(word)\n",
    "    else:\n",
    "        print(i,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tinkoff_embedding_matrix = np.zeros((MAX_NB_WORDS, len(w2v_model.wv.word_vec('1'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/ops.py:763: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = lib.scalar_compare(x, y, op)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "rarest_word=data_parse.sort_values(by=['tokenizer'],ascending=False)[data_parse['tinkoff_wv']!='not_found']['tinkoff_wv'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if word in w2v_model.wv.vocab:\n",
    "        tinkoff_embedding_matrix[i-1] = w2v_model.wv.word_vec(word)\n",
    "    elif '1' in np.unique(list(word)):\n",
    "        tinkoff_embedding_matrix[i-1] = w2v_model.wv.word_vec('11')\n",
    "    else:\n",
    "        tinkoff_embedding_matrix[i-1] = rarest_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Таргеты предложений и диалогов также преобразуются в последовательности номеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31734/31734 [00:09<00:00, 3404.29it/s]\n"
     ]
    }
   ],
   "source": [
    "sent_targ=[]\n",
    "k=0\n",
    "for i in tqdm(range(len(W_sent_parse))):\n",
    "    \n",
    "    sent_targ.append(np.array(data_parse[k:(k+len(W_sent_parse[i]))]['targ']))\n",
    "    k=k+len(W_sent_parse[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3856/3856 [00:06<00:00, 621.48it/s]\n"
     ]
    }
   ],
   "source": [
    "dialog_targ=[]\n",
    "for i in tqdm(range(data_parse['text'].max())):\n",
    "    dialog_targ.append(np.array(data_parse[data_parse['text']==i]['targ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Таблица со всеми словами и таблица с тагргетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_parse.pickle', 'wb') as f:\n",
    "    pickle.dump(data_parse, f)\n",
    "with open('data_targ.pickle', 'wb') as f:\n",
    "    pickle.dump(data_targ, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Список из предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('W_sent_parse.pickle', 'wb') as f:\n",
    "    pickle.dump(W_sent_parse, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Обученный word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('model_wv_parse.pickle', 'wb') as f:\n",
    "    pickle.dump(model_wv_parse, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Токенизированные предложения и диалоги и их таргеты (использовать для обучения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('sentences.pickle', 'wb') as f:\n",
    "    pickle.dump(sentences, f)\n",
    "with open('dialogs.pickle', 'wb') as f:\n",
    "    pickle.dump(sentences, f)\n",
    "with open('sent_targ.pickle', 'wb') as f:\n",
    "    pickle.dump(sent_targ, f)\n",
    "with open('dialog_targ.pickle', 'wb') as f:\n",
    "    pickle.dump(dialog_targ, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Индексы токенов и embedding matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('word_index.pickle', 'wb') as f:\n",
    "    pickle.dump(word_index, f)\n",
    "with open('my_embedding_matrix.pickle', 'wb') as f:\n",
    "    pickle.dump(my_embedding_matrix, f)\n",
    "with open('tinkoff_embedding_matrix.pickle', 'wb') as f:\n",
    "    pickle.dump(tinkoff_embedding_matrix, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Обучение модели на размеченных предложениях из первых 3000 диалогов и валидация на оставшихся диалогах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Flatten, Dense, Input, LSTM, Embedding, Dropout, Activation, Merge, Bidirectional, SimpleRNN, GRU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('data_parse.pickle', 'rb') as f:\n",
    "    data_parse = pickle.load(f)\n",
    "with open('data_targ.pickle', 'rb') as f:\n",
    "    data_targ = pickle.load(f)\n",
    "with open('W_sent_parse.pickle', 'rb') as f:\n",
    "    W_sent_parse = pickle.load(f)\n",
    "with open('sentences.pickle', 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "with open('sent_targ.pickle', 'rb') as f:\n",
    "    sent_targ = pickle.load(f)\n",
    "with open('word_index.pickle', 'rb') as f:\n",
    "    word_index = pickle.load(f)\n",
    "with open('my_embedding_matrix.pickle', 'rb') as f:\n",
    "    embedding_matrix = pickle.load(f)\n",
    "with open('model_wv_parse.pickle', 'rb') as f:\n",
    "    model_wv_parse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = embedding_matrix.shape[0]\n",
    "EMBEDDING_DIM = embedding_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31734/31734 [00:00<00:00, 46791.92it/s]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "for i in tqdm(range(len(sent_targ))):\n",
    "    if (np.unique(sent_targ[i])).max()>1:\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "k=27500\n",
    "s=np.array([len(n) for n in sentences[:k]]).sum()\n",
    "while s<len(data_parse[data_parse['text']<3000]):\n",
    "    s=s+len(sentences[k])\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train=np.array(sentences)[np.array(labels)[np.array(labels)<k]]\n",
    "y_train=np.array(sent_targ)[np.array(labels)[np.array(labels)<k]]\n",
    "val=np.array(sentences)[np.array(labels)[np.array(labels)>=k]]\n",
    "y_val=np.array(sent_targ)[np.array(labels)[np.array(labels)>=k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_cat=np.array([to_categorical(sent_label, num_classes=11).astype(int) for sent_label in list(y_train)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В качестве модели используются нейронная сеть из нескольких слоев. Входной слой это уже обученный embedding matrix, сопоставляющий каждому токену-слову его вектор word2vec. Второй слой Bidirectional LSTM слой - реккурентный слой, обладающий длинной и короткой памятью, который позволяет обрабатывать последовательность слов в двух направлениях (прямом и обратном)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py:1993: UserWarning: RNN dropout is no longer supported with the Theano backend due to technical limitations. You can either set `dropout` and `recurrent_dropout` to 0, or use the TensorFlow backend.\n",
      "  'RNN dropout is no longer supported with the Theano backend '\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(TimeDistributed(Dense(11, activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',                                   \n",
    "              optimizer='rmsprop',                                               \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Обучаем сеть на батчах, соотвествующих преддложениям из первых 3000 диалогов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3934 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [04:23<00:00, 14.93it/s] \n",
      "  0%|          | 3/3934 [00:00<02:28, 26.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:31<00:00, 18.61it/s]\n",
      "  0%|          | 3/3934 [00:00<02:29, 26.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:56<00:00, 16.60it/s]\n",
      "  0%|          | 3/3934 [00:00<02:19, 28.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:39<00:00, 17.90it/s]\n",
      "  0%|          | 3/3934 [00:00<02:30, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:54<00:00, 16.79it/s]\n",
      "  0%|          | 4/3934 [00:00<01:58, 33.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:35<00:00, 18.28it/s]\n",
      "  0%|          | 4/3934 [00:00<02:01, 32.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:29<00:00, 18.82it/s]\n",
      "  0%|          | 3/3934 [00:00<02:36, 25.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:42<00:00, 13.52it/s]\n",
      "  0%|          | 2/3934 [00:00<04:11, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [03:51<00:00, 23.66it/s]\n",
      "  0%|          | 3/3934 [00:00<02:42, 24.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3934/3934 [04:18<00:00, 15.23it/s]\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 1\n",
    "for e in range(nb_epoch):\n",
    "    print(\"Epoch:%d\" % (e+1))\n",
    "    for d in tqdm(range(len(train))):\n",
    "        batch_samples = np.expand_dims(train[d], axis=0)\n",
    "        batch_labels =np.expand_dims(y_train_cat[d], axis=0)\n",
    "        model.train_on_batch(batch_samples, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "f1-score на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 967/967 [00:04<00:00, 208.13it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "for v in tqdm(val):\n",
    "    preds = model.predict(np.expand_dims(v, axis=0))\n",
    "    y_pred.append(np.array([np.argmax(pred,axis=1) for pred in preds]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5635540369077506"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(np.concatenate(y_val,axis=0),np.concatenate(y_pred,axis=0), average='macro')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
